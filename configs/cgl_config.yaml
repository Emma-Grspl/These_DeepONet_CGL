experiment_name: "CGL_Generalist_Solver"
device: "cuda"

physics:
  x_domain: [-20, 20]
  t_max: 10.0
  
  bounds:
    A: [0.1, 3.0]
    w0: [0.5, 6.0]
    x0: [0.0, 0.0]
    k: [-2.0, 2.0]

  equation_params:
    alpha: [0.0, 1.0]
    beta: [-1.5, 1.5]
    mu: [-0.5, 1.0]
    V: [-2.0, 2.0]

model:
  branch_input_dim: 9 
  trunk_input_dim: 2
  latent_dim: 256
  
  branch_layers: [256, 256, 256, 256, 256]
  trunk_layers: [256, 256, 256, 256]
  
  activation: "silu"
  
  fourier_dim: 64
  fourier_scales: [1.0, 2.0, 5.0, 10.0, 20.0, 40.0]

training:
  batch_size_ic: 4096   
  batch_size_pde: 4096   
  
  # --- NOUVEAU PARAMÈTRE ---
  max_retry: 4          # Nombre de tentatives Adam (avec division du LR) avant L-BFGS
  
  weights:
    ic_loss: 150.0      
    pde_loss: 80.0
    bc_loss: 50.0

  ic_phase:
    # On a augmenté ces valeurs pour que le Warmup Adam + LBFGS soit efficace
    iterations: 20000    # Augmenté de 10k à 20k
    learning_rate: 0.001 # Augmenté de 0.0002 à 0.001 pour converger plus vite avant LBFGS

# --- ATTENTION : CE BLOC DOIT ÊTRE À LA RACINE (PAS D'INDENTATION) ---
time_marching:
  dt_step: 0.05        
  iters_per_step: 5000  
  
  # Audit params
  audit_threshold: 0.05