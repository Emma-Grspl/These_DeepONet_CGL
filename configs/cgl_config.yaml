experiment_name: "CGL_Generalist_Solver_Lite"
device: "cuda"

physics:
  x_domain: [-20, 20]
  t_max: 5.0
  initial_conditions: [1, 2]
  bounds:
    A: [0.1, 3.0]
    w0: [0.5, 6.0]
    x0: [0.0, 0.0]
    k: [-2.0, 2.0]
  equation_params:
    alpha: [0.0, 1.0]
    beta: [-1.5, 1.5]
    mu: [-0.5, 1.0]
    V: [-2.0, 2.0]

model:
  branch_input_dim: 9 
  trunk_input_dim: 2
  latent_dim: 256              # <--- RÉDUIT (Était 512)
  
  branch_layers: [256, 256, 256, 256, 256] # <--- 5 couches au lieu de 6
  trunk_layers: [256, 256, 256, 256]       # <--- 4 couches suffisent
  
  activation: "silu"
  
  fourier_dim: 64
  fourier_scales: [1.0, 2.0, 5.0, 10.0, 20.0] # <--- SUPPRESSION du 40.0 (Trop bruitant)

training:
  batch_size_ic: 8192   
  batch_size_pde: 8192   
  
  # Stratégie Robustesse
  max_macro_loops: 6          # <--- RÉDUIT (Si ça marche pas en 6 coups, ça marchera pas en 8)
  nb_adam_retries: 2          # <--- CRITIQUE : Évite l'effondrement du LR (Divise max par 4)
  check_interval: 2000
  stagnation_threshold: 0.001

  # Équilibrage initial
  pde_weight_start: 0.2       
  pde_weight_target: 1.0
  ramp_end_t: 0.1

  weights:
    pde_loss: 0.5             # Sera écrasé par la rampe
    ic_loss_start: 5.0
    ic_loss_target: 2.0
    bc_loss: 1.0
    
  # Seuils Audit
  target_error_ic: 0.04       # 3%
  target_error_global: 0.045   # <--- LÉGER RELÂCHEMENT (4% au lieu de 3% pour fluidifier le début)

  ic_phase:
    learning_rate: 5e-4
    iterations: 10000

# -----------------------------

time_marching:
  learning_rate: 3e-4         # <--- AUGMENTÉ (Était 1e-4). 
                              # Avec le Soft Start (divisé par 2), ça commencera à 1.5e-4. C'est parfait.
  zones:
    - t_end: 0.1
      dt: 0.01
      iters: 10000            # <--- AUGMENTÉ : Modèle plus petit = on peut itérer plus vite.
    - t_end: 2.0
      dt: 0.05
      iters: 8000
    - t_end: 5.0
      dt: 0.1
      iters: 8000